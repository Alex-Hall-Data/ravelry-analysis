plot(test$animal,test$rating_average)
plot(test$yardage,test$rating_average)
plot(test$organic,test$rating_average)
plot(test$Alpaca,test$rating_average)
plot(test$company_yarns_count,test$rating_average)
plot(test$rating_average,test$rating_average)
plot(test$max_gauge,test$rating_average)
plot(test$Acrylic,test$rating_average)
plot(test$grams,test$rating_average)
plot(test$grams,test$yardage)
plot(test$rating_average,test$yardage)
plot(test$yardage,test$rating_average)
plot(test$Other,test$rating_average)
plot(terain$company_yarns_count,train$rating_average)
plot(train$company_yarns_count,train$rating_average)
plot(train$animal,train$rating_average)
plot(train$yardage,train$rating_average)
#Ensure working directory is that in which 'data' file is stored
#load in dataset
load("data.RData")
#yarn_data<-processed_dataset
#rm("processed_dataset")
#########################################################removeand uncomment above when done
set.seed(sample(c(1:100),1))
samples<-sample(c(1:nrow(processed_dataset)),2000)
yarn_data<-processed_dataset[samples,]
rm("processed_dataset")
###########################################################
library(e1071)
library(Metrics)
library(parallelSVM)
set.seed(57)
#generate training and testing sets
#test set is 20% of data
test_indices<-sample(nrow(yarn_data),floor(0.2*nrow(yarn_data)),replace=FALSE)
test<-yarn_data[test_indices,]
train<-yarn_data[-test_indices,]
set.seed(57)
#fit svm model to training data
#svmfit=svm(rating_average~., data=train , kernel ="radial", cost=1000000,gamma=0.00000001, scale=TRUE)
#svmfit=svm(rating_average~., data=train , kernel ="radial", cost=1000000,gamma=0.00001, scale=TRUE)
svmfit=svm(rating_average~synthetic, data=train , kernel ="radial", cost=100000,gamma=0.1, scale=TRUE)
#view support vectors
#svmfit$index
#plot(svmfit,train)
#predict - omits rows with NAS
predicted<-predict(svmfit,test[!rowSums(is.na(test)),])
#omit NAs from test data - note this halves the size. MAY CHANGE LATER
test<-test[!rowSums(is.na(test)),]
#plot actuals and predicted
plot(c(1:length(predicted)),test$rating_average,pch="o",col="black")
points(c(1:length(predicted)),predicted,pch="o",col="red")
#calculate mean RMS error
RMSerror<-rmse(test$rating_average,predicted)
RMSerror
plot(train$yardage,train$rating_average)
plot(train$yardage,train$rating_total)
plot(train$yardage,log(train$rating_total))
plot(train$yarn_weight_ply,log(train$rating_total))
plot(train$Silk,log(train$rating_total))
plot(train$synthetic,log(train$rating_total))
plot(train$wpi,log(train$rating_total))
plot(train$Merino,log(train$rating_total))
plot(train$max_needle_metric,log(train$rating_total))
plot(train$min_needle_metric,log(train$rating_total))
plot(train$Nylon,log(train$rating_total))
plot(yarn_data$animal,log(yarn_data$rating_total))
#SET SCALE-TRUE BEFORE RUNNING FULL DATASET
#Ensure working directory is that in which 'data' file is stored
#load in dataset
load("data.RData")
samples<-sample(c(1:nrow(processed_dataset)),2000)#ALTER THUS BEFORE RUNNING ON EC2
yarn_data<-processed_dataset[samples,]
#rm("processed_dataset")
library(e1071)
library(Metrics)
library(doParallel)
library(caret)
library(base)
start<-proc.time()
set.seed(57)
#create compute cluster
cl<-makeCluster(detectCores())
registerDoParallel(cl)
#create formula for svm
yarn_data<-yarn_data[,c(2,1,c(3:ncol(yarn_data)))]
form<-formula(yarn_data)
#create folds for CV
set.seed(57)
yarn_data$fold <- caret::createFolds(1:nrow(yarn_data), k = 5, list = FALSE) #try with 10 folds
#set parameter grid
cost <- c(1,1e2,1e3,1e7)
gamma <- c(1e-7,1e-5,1e-4,1e-3)
PG <- expand.grid(cost = cost, gamma = gamma)
#go through parameter grid with for loop – NOTE IF THIS DOESN’T WORK, JUST USE DOPAR ON THIS LOOP
result <- foreach(i = 1:nrow(PG), .combine = rbind) %:%
foreach(j = 1:max(yarn_data$fold), .combine = rbind, .inorder = FALSE) %dopar% {
#need to state libraries within parallisation section
require(foreach)
require(Metrics)
c <- PG[i, ]$cost
g <- PG[i, ]$gamma
#10 fold cv
training <- yarn_data[yarn_data$fold != j, ]
test<-yarn_data[yarn_data$fold == j, ]
training <- training[!rowSums(is.na(training)),]
test<-test[!rowSums(is.na(test)),]
svm.fit <- e1071::svm(form, data = training, kernel = "radial", cost = c, gamma = g, na.action=na.omit,scale=FALSE)
pred <- predict(svm.fit, test)
out<-data.frame(actual = test$rating_total, predicted = pred)
#determine performance for each variation of parameters
#this is the evaluation criterion – use RMS (or similar)
RMSerror<-rmse(out$actual,out$predicted)
data.frame(PG[i, ], RMSE = RMSerror)
}
library(httr)
library(httpuv)
library(xml2)
# user_rav.txt contains API username and password
credentials <- readLines("user_rav.txt")
names(credentials) <- c("user","access_key","secret_key")
OpenConnection <- function(credentials){
# Args: login info for the Ravelry API
# Returns oauth token
# Open connection to Ravelry API and return token
reqURL <- "https://www.ravelry.com/oauth/request_token"
accessURL <- "https://www.ravelry.com/oauth/access_token"
authURL <- "https://www.ravelry.com/oauth/authorize"
ravelry.app <- oauth_app("ravelry", key=credentials["access_key"],
secret=credentials["secret_key"])
ravelry.urls <- oauth_endpoint(reqURL, authURL, accessURL)
return(oauth1.0_token(ravelry.urls, ravelry.app))
}
# Quick test of API connection by getting connected user info
TestConnection <- function(ravelry.token) {
# Arg: API token
# Returns name of the user connected with this token
test <- GET("https://api.ravelry.com/current_user.json",
config=config("token"=ravelry.token))
print(content(test)$user$username)
}
ravelry.token <- OpenConnection(credentials)
TestConnection(ravelry.token)
setwd("~/R/ravelry")
library(httr)
library(httpuv)
library(xml2)
# user_rav.txt contains API username and password
credentials <- readLines("user_rav.txt")
names(credentials) <- c("user","access_key","secret_key")
OpenConnection <- function(credentials){
# Args: login info for the Ravelry API
# Returns oauth token
# Open connection to Ravelry API and return token
reqURL <- "https://www.ravelry.com/oauth/request_token"
accessURL <- "https://www.ravelry.com/oauth/access_token"
authURL <- "https://www.ravelry.com/oauth/authorize"
ravelry.app <- oauth_app("ravelry", key=credentials["access_key"],
secret=credentials["secret_key"])
ravelry.urls <- oauth_endpoint(reqURL, authURL, accessURL)
return(oauth1.0_token(ravelry.urls, ravelry.app))
}
# Quick test of API connection by getting connected user info
TestConnection <- function(ravelry.token) {
# Arg: API token
# Returns name of the user connected with this token
test <- GET("https://api.ravelry.com/current_user.json",
config=config("token"=ravelry.token))
print(content(test)$user$username)
}
ravelry.token <- OpenConnection(credentials)
TestConnection(ravelry.token)
library(httr)
library(httpuv)
library(xml2)
# user_rav.txt contains API username and password
credentials <- readLines("user_rav.txt")
names(credentials) <- c("user","access_key","secret_key")
OpenConnection <- function(credentials){
# Args: login info for the Ravelry API
# Returns oauth token
# Open connection to Ravelry API and return token
reqURL <- "https://www.ravelry.com/oauth/request_token"
accessURL <- "https://www.ravelry.com/oauth/access_token"
authURL <- "https://www.ravelry.com/oauth/authorize"
ravelry.app <- oauth_app("ravelry", key=credentials["access_key"],
secret=credentials["secret_key"])
ravelry.urls <- oauth_endpoint(reqURL, authURL, accessURL)
return(oauth1.0_token(ravelry.urls, ravelry.app))
}
# Quick test of API connection by getting connected user info
TestConnection <- function(ravelry.token) {
# Arg: API token
# Returns name of the user connected with this token
test <- GET("https://api.ravelry.com/current_user.json",
config=config("token"=ravelry.token))
print(content(test)$user$username)
}
ravelry.token <- OpenConnection(credentials)
TestConnection(ravelry.token)
yarn<-GET("https://api.ravelry.com/yarns/50000.json", config=config("token"=ravelry.token))
yarn
attributes(yarn)
yarn$response
content(yarn)
yarn<-GET("https://api.ravelry.com/yarns/50002.json", config=config("token"=ravelry.token))
content(yarn)
yarn<-GET("https://api.ravelry.com/yarns/67895.json", config=config("token"=ravelry.token))
content(yarn)
View(content(yarn))
View(content(yarn))$yarn$rating_total
yarn<content(yarn)
yarn<-content(yarn)
yarn$yarn$rating_total
load("~/R/ravelry/data/yarn_data.RData")
names(dataset)
dataset["id"==67895,]
dataset[id==67895,]
dataset["id"==67895,]
View(dataset["id"==67895,])
View(dataset[dataset$id==67895,])
load("~/R/ravelry/analysis/data.RData")
View(processed_dataset[processed_dataset$rating_total==53 & processed_dataset$yardage==400,])
View(processed_dataset[processed_dataset$rating_total==53 & processed_dataset$yardage==400 & processed_dataset$Merino==100,])
library(pls)
#load in raw dataset
load("~/R/ravelry/data/processed_dataset.RData")
#convert list columns to vectors
attrs<-names(processed_dataset)
#first 17 columns are lists in original dataset
for( j in (1:17)){
#replace nulls with zero
attr_vector<-c(processed_dataset[,j])
for (i in(1:length(attr_vector))){
if(is.null(attr_vector[i][[1]])==TRUE){
attr_vector[i]<-0}
else{attr_vector[i]<-attr_vector[i]}
}
attr_vector<-unlist(attr_vector)
processed_dataset[,j]<-attr_vector
}
#================================================================================================
#Remove attributes with no info, or just text
#remove hook size attributes - hook size is completely dependant on needle size so gives no new info
drops<-grep('hook',attrs,TRUE)
processed_dataset<-processed_dataset[,-drops]
#remove attributes which are unlikely to carry any useful information (text attributes)
drops<-c("permalink","name","company_name","company_permalink")
processed_dataset<-processed_dataset[ , !(names(processed_dataset) %in% drops)]
#remove 'texture' and 'needle name' attributes. The former is text based. The latter are dependant on needle size
drops<-c("texture","max_needle_name","min_needle_name")
processed_dataset<-processed_dataset[ , !(names(processed_dataset) %in% drops)]
#yarn weight names could be converted to dummy variables, but this is pointless since it is dependant on ply - remove
drops<-c("yarn_weight_name")
processed_dataset<-processed_dataset[ , !(names(processed_dataset) %in% drops)]
#now delete all 'id' attributes - these contain no information
drops<-c("company_id","min_needle_id","max_needle_id","yarn_weight_id") #RE ENTER ID HERE
processed_dataset<-processed_dataset[ , !(names(processed_dataset) %in% drops)]
#remove average rating and rating count since the relationship between these and overall rating is trivial
drops<-c("rating_average","rating_count")
processed_dataset<-processed_dataset[ , !(names(processed_dataset) %in% drops)]
#most needle size attributes can be removed since they are just variatins of the same measurement (metric, imperial etc)
drops<-c("max_needle_pretty_metric","max_needle_crochet","max_needle_us","max_needle_us_steel",
"max_needle_knitting","min_needle_pretty_metric","min_needle_crochet","min_needle_us","min_needle_us_steel",
"min_needle_knitting","yarn_weight_min_gauge","yarn_weight_wpi","yarn_weight_max_gauge",
"yarn_weight_knit_gauge","yarn_weight_crochet_gauge")
processed_dataset<-processed_dataset[ , !(names(processed_dataset) %in% drops)]
#convert allattributes to
processed_dataset <- as.data.frame(sapply(processed_dataset, as.numeric))
#=================================================================================================
#Make new dependant attributes for fiber types (plant, animal or synthetic)
#create new columns for the new attributes
vegetable<-rep(0,nrow(processed_dataset))
animal<-rep(0,nrow(processed_dataset))
synthetic<-rep(0,nrow(processed_dataset))
#list attribute names
vegetable_names<-c("Cotton", "Linen", "Bamboo","Soy","Plant fiber","Hemp","Tencel")
animal_names<-c("Wool","Mohair","Merino","Silk","Angora","Cashmere","Alpaca","Llama",
"Camel","Bison","Yak","Qiviut")
synthetic_names<-c("Nylon","Rayon","Acryllic","Polyester","Metallic","Microfiber")
processed_dataset<-cbind(processed_dataset,vegetable,animal,synthetic)
#create totals (note no NAs since these were previously replaced with zeros)
processed_dataset$vegetable<-rowSums(processed_dataset[,names(processed_dataset) %in% vegetable_names])
processed_dataset$animal<-rowSums(processed_dataset[,names(processed_dataset) %in% animal_names])
processed_dataset$synthetic<-rowSums(processed_dataset[,names(processed_dataset) %in% synthetic_names])
#note, the 'other' attribute is for fibers of unknown type. May wish to consider this similarly to the above atributes
#=================================================================================================
#We are now left with 44 attributes for analysis
#remove thread size attribute as it is constant (no info and doesn't allow scaling)
#remove average rating and rating count since the relationship between these and overall rating is trivial
drops<-c("thread_size")
processed_dataset<-processed_dataset[ , !(names(processed_dataset) %in% drops)]
#standardise the data prior to any model fitting
#processed_dataset<-scale(processed_dataset)
set.seed(57)
#perform PCA (set scale=T to standardise dataset). NAS OMITTED (note, removed second column since this is the dependant variable)
pca=prcomp( na.omit(processed_dataset[,-2]), scale=TRUE)
#get varience of each principal component
pca.var<-pca$sdev^2
#get proportion of varience explained by each principal component
pca.pve=pca.var/sum(pca.var)
#plot proportion of varience explained by each PC:
barplot(pca.pve , xlab=" Principal Component ", ylab="Proportion of
Variance Explained ", ylim=c(0,max(pca.pve)))
#perform PCR
set.seed (57)
pcr_model <- pcr(rating_total~., data = na.omit(processed_dataset), scale = TRUE, validation = "CV")
#validation plot for the pcr model with cross-validation MSE plotted
validationplot(pcr_model,val.type="MSEP")
#we see that the lowest MSE occurs when alomst all variables are used
View(processed_dataset[processed_dataset$id==67895])
View(processed_dataset[processed_dataset$id==67895,])
library(httr)
library(httpuv)
library(xml2)
# user_rav.txt contains API username and password
credentials <- readLines("user_rav.txt")
names(credentials) <- c("user","access_key","secret_key")
OpenConnection <- function(credentials){
# Args: login info for the Ravelry API
# Returns oauth token
# Open connection to Ravelry API and return token
reqURL <- "https://www.ravelry.com/oauth/request_token"
accessURL <- "https://www.ravelry.com/oauth/access_token"
authURL <- "https://www.ravelry.com/oauth/authorize"
ravelry.app <- oauth_app("ravelry", key=credentials["access_key"],
secret=credentials["secret_key"])
ravelry.urls <- oauth_endpoint(reqURL, authURL, accessURL)
return(oauth1.0_token(ravelry.urls, ravelry.app))
}
# Quick test of API connection by getting connected user info
TestConnection <- function(ravelry.token) {
# Arg: API token
# Returns name of the user connected with this token
test <- GET("https://api.ravelry.com/current_user.json",
config=config("token"=ravelry.token))
print(content(test)$user$username)
}
ravelry.token <- OpenConnection(credentials)
TestConnection(ravelry.token)
yarn<-GET("https://api.ravelry.com/yarns/5000.json", config=config("token"=ravelry.token))
yarn<-GET("https://api.ravelry.com/yarns/35946.json", config=config("token"=ravelry.token))
content(yarn)
content(yarn)
library(pls)
#load in raw dataset
load("~/R/ravelry/data/processed_dataset.RData")
#convert list columns to vectors
attrs<-names(processed_dataset)
#first 17 columns are lists in original dataset
for( j in (1:17)){
#replace nulls with zero
attr_vector<-c(processed_dataset[,j])
for (i in(1:length(attr_vector))){
if(is.null(attr_vector[i][[1]])==TRUE){
attr_vector[i]<-0}
else{attr_vector[i]<-attr_vector[i]}
}
attr_vector<-unlist(attr_vector)
processed_dataset[,j]<-attr_vector
}
#================================================================================================
#Remove attributes with no info, or just text
#remove hook size attributes - hook size is completely dependant on needle size so gives no new info
drops<-grep('hook',attrs,TRUE)
processed_dataset<-processed_dataset[,-drops]
#remove attributes which are unlikely to carry any useful information (text attributes)
drops<-c("permalink","name","company_name","company_permalink")
processed_dataset<-processed_dataset[ , !(names(processed_dataset) %in% drops)]
#remove 'texture' and 'needle name' attributes. The former is text based. The latter are dependant on needle size
drops<-c("texture","max_needle_name","min_needle_name")
processed_dataset<-processed_dataset[ , !(names(processed_dataset) %in% drops)]
#yarn weight names could be converted to dummy variables, but this is pointless since it is dependant on ply - remove
drops<-c("yarn_weight_name")
processed_dataset<-processed_dataset[ , !(names(processed_dataset) %in% drops)]
#now delete all 'id' attributes - these contain no information
drops<-c("company_id","min_needle_id","max_needle_id","yarn_weight_id") #RE ENTER ID HERE
processed_dataset<-processed_dataset[ , !(names(processed_dataset) %in% drops)]
#remove average rating and rating count since the relationship between these and overall rating is trivial
drops<-c("rating_average","rating_count")
processed_dataset<-processed_dataset[ , !(names(processed_dataset) %in% drops)]
#most needle size attributes can be removed since they are just variatins of the same measurement (metric, imperial etc)
drops<-c("max_needle_pretty_metric","max_needle_crochet","max_needle_us","max_needle_us_steel",
"max_needle_knitting","min_needle_pretty_metric","min_needle_crochet","min_needle_us","min_needle_us_steel",
"min_needle_knitting","yarn_weight_min_gauge","yarn_weight_wpi","yarn_weight_max_gauge",
"yarn_weight_knit_gauge","yarn_weight_crochet_gauge")
processed_dataset<-processed_dataset[ , !(names(processed_dataset) %in% drops)]
#convert allattributes to
processed_dataset <- as.data.frame(sapply(processed_dataset, as.numeric))
#=================================================================================================
#Make new dependant attributes for fiber types (plant, animal or synthetic)
#create new columns for the new attributes
vegetable<-rep(0,nrow(processed_dataset))
animal<-rep(0,nrow(processed_dataset))
synthetic<-rep(0,nrow(processed_dataset))
#list attribute names
vegetable_names<-c("Cotton", "Linen", "Bamboo","Soy","Plant fiber","Hemp","Tencel")
animal_names<-c("Wool","Mohair","Merino","Silk","Angora","Cashmere","Alpaca","Llama",
"Camel","Bison","Yak","Qiviut")
synthetic_names<-c("Nylon","Rayon","Acryllic","Polyester","Metallic","Microfiber")
processed_dataset<-cbind(processed_dataset,vegetable,animal,synthetic)
#create totals (note no NAs since these were previously replaced with zeros)
processed_dataset$vegetable<-rowSums(processed_dataset[,names(processed_dataset) %in% vegetable_names])
processed_dataset$animal<-rowSums(processed_dataset[,names(processed_dataset) %in% animal_names])
processed_dataset$synthetic<-rowSums(processed_dataset[,names(processed_dataset) %in% synthetic_names])
#note, the 'other' attribute is for fibers of unknown type. May wish to consider this similarly to the above atributes
#=================================================================================================
#We are now left with 44 attributes for analysis
#remove thread size attribute as it is constant (no info and doesn't allow scaling)
#remove average rating and rating count since the relationship between these and overall rating is trivial
drops<-c("thread_size")
processed_dataset<-processed_dataset[ , !(names(processed_dataset) %in% drops)]
#standardise the data prior to any model fitting
#processed_dataset<-scale(processed_dataset)
set.seed(57)
#perform PCA (set scale=T to standardise dataset). NAS OMITTED (note, removed second column since this is the dependant variable)
pca=prcomp( na.omit(processed_dataset[,-2]), scale=TRUE)
#get varience of each principal component
pca.var<-pca$sdev^2
#get proportion of varience explained by each principal component
pca.pve=pca.var/sum(pca.var)
#plot proportion of varience explained by each PC:
barplot(pca.pve , xlab=" Principal Component ", ylab="Proportion of
Variance Explained ", ylim=c(0,max(pca.pve)))
#perform PCR
set.seed (57)
pcr_model <- pcr(rating_total~., data = na.omit(processed_dataset), scale = TRUE, validation = "CV")
#validation plot for the pcr model with cross-validation MSE plotted
validationplot(pcr_model,val.type="MSEP")
#we see that the lowest MSE occurs when alomst all variables are used
View(processed_dataset[processed_dataset$id==35946,])
library(httr)
library(httpuv)
library(xml2)
# user_rav.txt contains API username and password
credentials <- readLines("user_rav.txt")
names(credentials) <- c("user","access_key","secret_key")
OpenConnection <- function(credentials){
# Args: login info for the Ravelry API
# Returns oauth token
# Open connection to Ravelry API and return token
reqURL <- "https://www.ravelry.com/oauth/request_token"
accessURL <- "https://www.ravelry.com/oauth/access_token"
authURL <- "https://www.ravelry.com/oauth/authorize"
ravelry.app <- oauth_app("ravelry", key=credentials["access_key"],
secret=credentials["secret_key"])
ravelry.urls <- oauth_endpoint(reqURL, authURL, accessURL)
return(oauth1.0_token(ravelry.urls, ravelry.app))
}
# Quick test of API connection by getting connected user info
TestConnection <- function(ravelry.token) {
# Arg: API token
# Returns name of the user connected with this token
test <- GET("https://api.ravelry.com/current_user.json",
config=config("token"=ravelry.token))
print(content(test)$user$username)
}
ravelry.token <- OpenConnection(credentials)
TestConnection(ravelry.token)
yarn<-GET("https://api.ravelry.com/yarns/35946.json", config=config("token"=ravelry.token))
yarn<-content(yarn)
yarn$yarn$rating_total
setwd("~/R/ravelry/analysis/ec2")
load("~/R/ravelry/analysis/ec2/data.RData")
#SET SCALE-TRUE BEFORE RUNNING FULL DATASET
#Ensure working directory is that in which 'data' file is stored
#load in dataset
load("data.RData")
yarn_data<-processed_dataset
rm("processed_dataset")
library(e1071)
library(Metrics)
library(doParallel)
library(caret)
library(base)
start<-proc.time()
set.seed(57)
#create compute cluster
cl<-makeCluster(detectCores())
registerDoParallel(cl)
#create formula for svm
yarn_data<-yarn_data[,c(2,1,c(3:ncol(yarn_data)))]
form<-formula(yarn_data)
#create folds for CV
set.seed(57)
yarn_data$fold <- caret::createFolds(1:nrow(yarn_data), k = 5, list = FALSE) #try with 10 folds
#set parameter grid
cost <- c(1,1e2,1e3,1e7)
gamma <- c(1e-7,1e-5,1e-4,1)
PG <- expand.grid(cost = cost, gamma = gamma)
#go through parameter grid with for loop – NOTE IF THIS DOESN’T WORK, JUST USE DOPAR ON THIS LOOP
result <- foreach(i = 1:nrow(PG), .combine = rbind) %:%
foreach(j = 1:max(yarn_data$fold), .combine = rbind, .inorder = FALSE) %dopar% {
#need to state libraries within parallisation section
require(foreach)
require(Metrics)
c <- PG[i, ]$cost
g <- PG[i, ]$gamma
#10 fold cv
training <- yarn_data[yarn_data$fold != j, ]
test<-yarn_data[yarn_data$fold == j, ]
training <- training[!rowSums(is.na(training)),]
test<-test[!rowSums(is.na(test)),]
svm.fit <- e1071::svm(form, data = training, kernel = "radial", cost = c, gamma = g, na.action=na.omit,scale=TRUE)
pred <- predict(svm.fit, test)
out<-data.frame(actual = test$rating_total, predicted = pred)
#determine performance for each variation of parameters
#this is the evaluation criterion – use RMS (or similar)
RMSerror<-rmse(out$actual,out$predicted)
data.frame(PG[i, ], RMSE = RMSerror)
}
setwd("~/R/ravelry/analysis/ec2")
